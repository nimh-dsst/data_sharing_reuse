{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, f1_score, precision_score, recall_score\n",
    "\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from urlextract import URLExtract\n",
    "\n",
    "import re\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.features.build_features import syns, sep_urls, check_paren, repo_label\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are trying to use two classifiers at once. One that is relatively high recall, and a second that is relatively high precision. After training them both on the same data, we apply both to the test set and only take the items that were labeled by both as true positives. \n",
    "\n",
    "Generally, this doesn't perform as we wanted. Even among the subset of true positives identified by the high recall classifier, the high precision still does not accurately label some as true positives. In other words, the recall of the high-precision calssifier is middling on the full test set, and is middling on the test set that is more constrained to those that are just identified as probable data statements by the high recall classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = URLExtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_statement</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>section</th>\n",
       "      <th>text</th>\n",
       "      <th>Journal Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Page</th>\n",
       "      <th>PMCID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>cv_run0</th>\n",
       "      <th>cv_run1</th>\n",
       "      <th>cv_run2</th>\n",
       "      <th>cv_run3</th>\n",
       "      <th>cv_run4</th>\n",
       "      <th>cv_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1007/s11481-008-9113-7</td>\n",
       "      <td>2581635</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>In the Golgi-impregnation experiment we found ...</td>\n",
       "      <td>J Neuroimmune Pharmacol</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>241</td>\n",
       "      <td>PMC2581635</td>\n",
       "      <td>18594991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1016/j.biopsych.2008.07.009</td>\n",
       "      <td>2586327</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>The individuals with at least 3 usable voxels ...</td>\n",
       "      <td>Biol Psychiatry</td>\n",
       "      <td>2008</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>856</td>\n",
       "      <td>PMC2586327</td>\n",
       "      <td>18707679</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1016/j.brainres.2008.07.008</td>\n",
       "      <td>2612637</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>Although our procedure was intended to target ...</td>\n",
       "      <td>Brain Res</td>\n",
       "      <td>2008</td>\n",
       "      <td>1230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202</td>\n",
       "      <td>PMC2612637</td>\n",
       "      <td>18662678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1371/journal.pone.0004156</td>\n",
       "      <td>2612746</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>low status face pictures, and included genotyp...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>e4156</td>\n",
       "      <td>PMC2612746</td>\n",
       "      <td>19142220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1016/j.neuron.2008.07.022</td>\n",
       "      <td>2614916</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>For each word, participants made a recognition...</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>2008</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>547</td>\n",
       "      <td>PMC2614916</td>\n",
       "      <td>18760691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_statement                             doi    pmcid  section  \\\n",
       "0               0       10.1007/s11481-008-9113-7  2581635  DISCUSS   \n",
       "1               0  10.1016/j.biopsych.2008.07.009  2586327  METHODS   \n",
       "2               0  10.1016/j.brainres.2008.07.008  2612637  METHODS   \n",
       "3               0    10.1371/journal.pone.0004156  2612746  METHODS   \n",
       "4               0    10.1016/j.neuron.2008.07.022  2614916  METHODS   \n",
       "\n",
       "                                                text            Journal Title  \\\n",
       "0  In the Golgi-impregnation experiment we found ...  J Neuroimmune Pharmacol   \n",
       "1  The individuals with at least 3 usable voxels ...          Biol Psychiatry   \n",
       "2  Although our procedure was intended to target ...                Brain Res   \n",
       "3  low status face pictures, and included genotyp...                 PLoS One   \n",
       "4  For each word, participants made a recognition...                   Neuron   \n",
       "\n",
       "   Year Volume Issue   Page       PMCID      PMID  cv_run0  cv_run1  cv_run2  \\\n",
       "0  2008      3     4    241  PMC2581635  18594991        0        0        0   \n",
       "1  2008     64    10    856  PMC2586327  18707679        0        0        0   \n",
       "2  2008   1230   NaN    202  PMC2612637  18662678        0        0        0   \n",
       "3  2009      4     1  e4156  PMC2612746  19142220        0        0        0   \n",
       "4  2008     59     4    547  PMC2614916  18760691        0        0        0   \n",
       "\n",
       "   cv_run3  cv_run4  cv_sum  \n",
       "0        0        0       0  \n",
       "1        0        0       0  \n",
       "2        0        0       0  \n",
       "3        0        0       0  \n",
       "4        0        0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/data/riddleta/data_sharing_reuse/external/combined_labels_incomplete.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text.fillna('', inplace=True)\n",
    "df['has_url'] = df.text.apply(lambda x: extract.has_urls(x))\n",
    "df['has_parenth'] = df.text.apply(lambda x: check_paren(x))\n",
    "df['repo'] = df.text.apply(lambda x: repo_label(x))\n",
    "df['text'] = df.text.apply(lambda x: sep_urls(x))\n",
    "df['syn_text'] = df.text.apply(lambda x: syns(x))\n",
    "df['all_text'] = df.text + ' ' + df.syn_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_repo_mentioned      2360\n",
       "dbgap                    43\n",
       "github                   30\n",
       "fcon_1000.projects       18\n",
       "nitrc                    16\n",
       " ndar                    11\n",
       "loni.usc.edu             10\n",
       "brain-map.org             9\n",
       "osf.io                    9\n",
       "humanconnectome.org       9\n",
       "(ndar)                    8\n",
       "zenodo                    4\n",
       "figshare                  2\n",
       "dryad                     2\n",
       "openneuro                 1\n",
       "fmridc                    1\n",
       "Name: repo, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words=stop_words.ENGLISH_STOP_WORDS)\n",
    "enc = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_tst, y_tr, y_tst = train_test_split(df.all_text, df.data_statement, test_size=.25, random_state=42, stratify=df.data_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0   1\n",
      "True              \n",
      "0          551  30\n",
      "1            2  51\n",
      "Predicted    0   1\n",
      "True              \n",
      "0          579   2\n",
      "1           16  37\n"
     ]
    }
   ],
   "source": [
    "x_train = cv.fit_transform(x_tr)\n",
    "one_hots_train = enc.fit_transform(df[['section', 'Journal Title', 'Year', 'has_url', 'has_parenth', 'repo']].loc[x_tr.index])\n",
    "y_train = df.data_statement[x_tr.index]\n",
    "x_test = cv.transform(df.all_text[x_tst.index])\n",
    "one_hots_test = enc.transform(df[['section', 'Journal Title', 'Year', 'has_url', 'has_parenth', 'repo']].iloc[x_tst.index])\n",
    "y_test = df.data_statement[x_tst.index]\n",
    "\n",
    "x_train = hstack([x_train, one_hots_train])\n",
    "x_test = hstack([x_test, one_hots_test])\n",
    "\n",
    "clf_high_rec = EasyEnsembleClassifier()\n",
    "clf_high_prec = RandomForestClassifier()\n",
    "\n",
    "y_score_high_rec = clf_high_rec.fit(x_train, y_train)\n",
    "y_score_high_prec = clf_high_prec.fit(x_train, y_train)\n",
    "y_pred_high_rec = clf_high_rec.predict(x_test)\n",
    "y_pred_high_prec = clf_high_prec.predict(x_test)\n",
    "print(pd.crosstab(y_test, y_pred_high_rec, rownames=['True'], colnames=['Predicted']))\n",
    "print(pd.crosstab(y_test, y_pred_high_prec, rownames=['True'], colnames=['Predicted']))\n",
    "\n",
    "df_test = df.loc[x_tst.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['high_rec_pred'] = y_pred_high_rec\n",
    "df_test['high_prec_pred'] = y_pred_high_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['overall_pred'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.overall_pred[(df_test.high_rec_pred==1) & (df_test.high_prec_pred == 1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    595\n",
       "1     39\n",
       "Name: overall_pred, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.overall_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0   1\n",
      "True              \n",
      "0          579   2\n",
      "1           16  37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       581\n",
      "           1       0.95      0.70      0.80        53\n",
      "\n",
      "    accuracy                           0.97       634\n",
      "   macro avg       0.96      0.85      0.89       634\n",
      "weighted avg       0.97      0.97      0.97       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(y_test, df_test.overall_pred, rownames=['True'], colnames=['Predicted']))\n",
    "print(classification_report(y_test, df_test.overall_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_sharing_reuse] *",
   "language": "python",
   "name": "conda-env-data_sharing_reuse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
