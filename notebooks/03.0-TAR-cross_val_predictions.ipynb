{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, f1_score, precision_score, recall_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from urlextract import URLExtract\n",
    "\n",
    "import re\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.features.build_features import syns, sep_urls, check_paren, repo_label\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = URLExtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_statement</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>section</th>\n",
       "      <th>text</th>\n",
       "      <th>Journal Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Page</th>\n",
       "      <th>PMCID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>cv_run0</th>\n",
       "      <th>cv_run1</th>\n",
       "      <th>cv_run2</th>\n",
       "      <th>cv_run3</th>\n",
       "      <th>cv_run4</th>\n",
       "      <th>cv_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1007/s11481-008-9113-7</td>\n",
       "      <td>2581635</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>In the Golgi-impregnation experiment we found ...</td>\n",
       "      <td>J Neuroimmune Pharmacol</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>241</td>\n",
       "      <td>PMC2581635</td>\n",
       "      <td>18594991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1016/j.biopsych.2008.07.009</td>\n",
       "      <td>2586327</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>The individuals with at least 3 usable voxels ...</td>\n",
       "      <td>Biol Psychiatry</td>\n",
       "      <td>2008</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>856</td>\n",
       "      <td>PMC2586327</td>\n",
       "      <td>18707679</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1016/j.brainres.2008.07.008</td>\n",
       "      <td>2612637</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>Although our procedure was intended to target ...</td>\n",
       "      <td>Brain Res</td>\n",
       "      <td>2008</td>\n",
       "      <td>1230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202</td>\n",
       "      <td>PMC2612637</td>\n",
       "      <td>18662678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1371/journal.pone.0004156</td>\n",
       "      <td>2612746</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>low status face pictures, and included genotyp...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>e4156</td>\n",
       "      <td>PMC2612746</td>\n",
       "      <td>19142220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1016/j.neuron.2008.07.022</td>\n",
       "      <td>2614916</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>For each word, participants made a recognition...</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>2008</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>547</td>\n",
       "      <td>PMC2614916</td>\n",
       "      <td>18760691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_statement                             doi    pmcid  section  \\\n",
       "0               0       10.1007/s11481-008-9113-7  2581635  DISCUSS   \n",
       "1               0  10.1016/j.biopsych.2008.07.009  2586327  METHODS   \n",
       "2               0  10.1016/j.brainres.2008.07.008  2612637  METHODS   \n",
       "3               0    10.1371/journal.pone.0004156  2612746  METHODS   \n",
       "4               0    10.1016/j.neuron.2008.07.022  2614916  METHODS   \n",
       "\n",
       "                                                text            Journal Title  \\\n",
       "0  In the Golgi-impregnation experiment we found ...  J Neuroimmune Pharmacol   \n",
       "1  The individuals with at least 3 usable voxels ...          Biol Psychiatry   \n",
       "2  Although our procedure was intended to target ...                Brain Res   \n",
       "3  low status face pictures, and included genotyp...                 PLoS One   \n",
       "4  For each word, participants made a recognition...                   Neuron   \n",
       "\n",
       "   Year Volume Issue   Page       PMCID      PMID  cv_run0  cv_run1  cv_run2  \\\n",
       "0  2008      3     4    241  PMC2581635  18594991        0        0        0   \n",
       "1  2008     64    10    856  PMC2586327  18707679        0        0        0   \n",
       "2  2008   1230   NaN    202  PMC2612637  18662678        0        0        0   \n",
       "3  2009      4     1  e4156  PMC2612746  19142220        0        0        0   \n",
       "4  2008     59     4    547  PMC2614916  18760691        0        0        0   \n",
       "\n",
       "   cv_run3  cv_run4  cv_sum  \n",
       "0        0        0       0  \n",
       "1        0        0       0  \n",
       "2        0        0       0  \n",
       "3        0        0       0  \n",
       "4        0        0       0  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/data/riddleta/data_sharing_reuse/external/combined_labels_incomplete.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text.fillna('', inplace=True)\n",
    "df['has_url'] = df.text.apply(lambda x: extract.has_urls(x))\n",
    "df['has_parenth'] = df.text.apply(lambda x: check_paren(x))\n",
    "df['repo'] = df.text.apply(lambda x: repo_label(x))\n",
    "df['text'] = df.text.apply(lambda x: sep_urls(x))\n",
    "df['syn_text'] = df.text.apply(lambda x: syns(x))\n",
    "df['all_text'] = df.text + ' ' + df.syn_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_run0\n",
      "cv_run1\n",
      "cv_run2\n",
      "cv_run3\n",
      "cv_run4\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "out_dat = df.copy()\n",
    "out_dat.drop(['cv_run0', 'cv_run1', 'cv_run2', 'cv_run3', 'cv_run4', 'cv_sum'], axis=1, inplace=True)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    s = 'cv_run'+str(i)\n",
    "    print(s)\n",
    "    out_dat[s] = -99\n",
    "    kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "    cv = CountVectorizer(stop_words=stop_words.ENGLISH_STOP_WORDS)\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    for train_index, test_index in kfold.split(df.all_text, df.data_statement):\n",
    "        x_train = cv.fit_transform(df.all_text[train_index])\n",
    "        one_hots_train = enc.fit_transform(df[['section', 'Journal Title', 'Year', 'has_url', 'has_parenth', 'repo']].iloc[train_index])\n",
    "        y_train = df.data_statement[train_index]\n",
    "        x_test = cv.transform(df.all_text[test_index])\n",
    "        one_hots_test = enc.transform(df[['section', 'Journal Title', 'Year', 'has_url', 'has_parenth', 'repo']].iloc[test_index])\n",
    "        y_test = df.data_statement[test_index]\n",
    "\n",
    "        x_train = hstack([x_train, one_hots_train])\n",
    "        x_test = hstack([x_test, one_hots_test])\n",
    "\n",
    "        clf = AdaBoostClassifier()\n",
    "        #y_score = clf.fit(x_res, y_res).decision_function(x_test)\n",
    "        y_score = clf.fit(x_train, y_train).decision_function(x_test)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        \n",
    "        out_dat[s].iloc[test_index] = y_pred\n",
    "\n",
    "    seed = seed+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dat['cv_sum'] = out_dat.cv_run0 + out_dat.cv_run1 + out_dat.cv_run2 + out_dat.cv_run3 + out_dat.cv_run4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dat.to_csv('/data/riddleta/data_sharing_reuse/processed/cross_val_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_sharing_reuse] *",
   "language": "python",
   "name": "conda-env-data_sharing_reuse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
