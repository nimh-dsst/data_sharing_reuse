{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riddleta/miniconda3/envs/data_sharing_reuse/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, f1_score, precision_score, recall_score\n",
    "\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from urlextract import URLExtract\n",
    "\n",
    "import re\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "import pickle\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.features.build_features import syns, sep_urls, check_paren, repo_label\n",
    "from src.data.make_dataset import return_passages, test_suitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = URLExtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_statement</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>section</th>\n",
       "      <th>text</th>\n",
       "      <th>Journal Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Page</th>\n",
       "      <th>PMCID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>cv_run0</th>\n",
       "      <th>cv_run1</th>\n",
       "      <th>cv_run2</th>\n",
       "      <th>cv_run3</th>\n",
       "      <th>cv_run4</th>\n",
       "      <th>cv_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1007/s11481-008-9113-7</td>\n",
       "      <td>2581635</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>In the Golgi-impregnation experiment we found ...</td>\n",
       "      <td>J Neuroimmune Pharmacol</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>241</td>\n",
       "      <td>PMC2581635</td>\n",
       "      <td>18594991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1016/j.biopsych.2008.07.009</td>\n",
       "      <td>2586327</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>The individuals with at least 3 usable voxels ...</td>\n",
       "      <td>Biol Psychiatry</td>\n",
       "      <td>2008</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>856</td>\n",
       "      <td>PMC2586327</td>\n",
       "      <td>18707679</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1016/j.brainres.2008.07.008</td>\n",
       "      <td>2612637</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>Although our procedure was intended to target ...</td>\n",
       "      <td>Brain Res</td>\n",
       "      <td>2008</td>\n",
       "      <td>1230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202</td>\n",
       "      <td>PMC2612637</td>\n",
       "      <td>18662678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1371/journal.pone.0004156</td>\n",
       "      <td>2612746</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>low status face pictures, and included genotyp...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>e4156</td>\n",
       "      <td>PMC2612746</td>\n",
       "      <td>19142220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1016/j.neuron.2008.07.022</td>\n",
       "      <td>2614916</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>For each word, participants made a recognition...</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>2008</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>547</td>\n",
       "      <td>PMC2614916</td>\n",
       "      <td>18760691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_statement                             doi    pmcid  section  \\\n",
       "0               0       10.1007/s11481-008-9113-7  2581635  DISCUSS   \n",
       "1               0  10.1016/j.biopsych.2008.07.009  2586327  METHODS   \n",
       "2               0  10.1016/j.brainres.2008.07.008  2612637  METHODS   \n",
       "3               0    10.1371/journal.pone.0004156  2612746  METHODS   \n",
       "4               0    10.1016/j.neuron.2008.07.022  2614916  METHODS   \n",
       "\n",
       "                                                text            Journal Title  \\\n",
       "0  In the Golgi-impregnation experiment we found ...  J Neuroimmune Pharmacol   \n",
       "1  The individuals with at least 3 usable voxels ...          Biol Psychiatry   \n",
       "2  Although our procedure was intended to target ...                Brain Res   \n",
       "3  low status face pictures, and included genotyp...                 PLoS One   \n",
       "4  For each word, participants made a recognition...                   Neuron   \n",
       "\n",
       "   Year Volume Issue   Page       PMCID      PMID  cv_run0  cv_run1  cv_run2  \\\n",
       "0  2008      3     4    241  PMC2581635  18594991        0        0        0   \n",
       "1  2008     64    10    856  PMC2586327  18707679        0        0        0   \n",
       "2  2008   1230   NaN    202  PMC2612637  18662678        0        0        0   \n",
       "3  2009      4     1  e4156  PMC2612746  19142220        0        0        0   \n",
       "4  2008     59     4    547  PMC2614916  18760691        0        0        0   \n",
       "\n",
       "   cv_run3  cv_run4  cv_sum  \n",
       "0        0        0       0  \n",
       "1        0        0       0  \n",
       "2        0        0       0  \n",
       "3        0        0       0  \n",
       "4        0        0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/data/riddleta/data_sharing_reuse/external/combined_labels_incomplete.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text.fillna('', inplace=True)\n",
    "df['has_url'] = df.text.apply(lambda x: extract.has_urls(x))\n",
    "df['has_parenth'] = df.text.apply(lambda x: check_paren(x))\n",
    "df['repo'] = df.text.apply(lambda x: repo_label(x))\n",
    "df['text'] = df.text.apply(lambda x: sep_urls(x))\n",
    "df['syn_text'] = df.text.apply(lambda x: syns(x))\n",
    "df['all_text'] = df.text + ' ' + df.syn_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words=stop_words.ENGLISH_STOP_WORDS)\n",
    "enc = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_tst, y_tr, y_tst = train_test_split(df.all_text, df.data_statement, test_size=.25, random_state=42, stratify=df.data_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0   1\n",
      "True              \n",
      "0          548  33\n",
      "1            3  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       581\n",
      "           1       0.60      0.94      0.74        53\n",
      "\n",
      "    accuracy                           0.94       634\n",
      "   macro avg       0.80      0.94      0.85       634\n",
      "weighted avg       0.96      0.94      0.95       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = cv.fit_transform(x_tr)\n",
    "one_hots_train = enc.fit_transform(df[['section', 'Journal Title', 'Year', 'has_url', 'has_parenth', 'repo']].loc[x_tr.index])\n",
    "y_train = df.data_statement[x_tr.index]\n",
    "x_test = cv.transform(df.all_text[x_tst.index])\n",
    "one_hots_test = enc.transform(df[['section', 'Journal Title', 'Year', 'has_url', 'has_parenth', 'repo']].iloc[x_tst.index])\n",
    "y_test = df.data_statement[x_tst.index]\n",
    "\n",
    "x_train = hstack([x_train, one_hots_train])\n",
    "x_test = hstack([x_test, one_hots_test])\n",
    "#x_res, y_res = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "clf = EasyEnsembleClassifier()\n",
    "#y_score = clf.fit(x_res, y_res).decision_function(x_test)\n",
    "y_score = clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted']))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riddleta/miniconda3/envs/data_sharing_reuse/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3050: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "nimh_papers = pd.read_csv('/data/riddleta/data_sharing_reuse/external/nimh_papers.csv')\n",
    "#load file index\n",
    "file_ix = pd.read_csv('/data/riddleta/data_sharing_reuse/external/file_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ix['pmcid'] = file_ix.pmcid.astype('str')\n",
    "nimh_papers['pmcid'] = nimh_papers.pmcid.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57692, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_papers = file_ix[file_ix.pmcid.isin(nimh_papers.pmcid)]\n",
    "target_papers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_papers = target_papers.sort_values('file')\n",
    "status_prints = range(0, len(target_papers.file.tolist()), 250)\n",
    "len(status_prints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n",
      "1750\n",
      "2000\n",
      "2250\n",
      "2500\n",
      "2750\n",
      "3000\n",
      "3250\n",
      "3500\n",
      "3750\n",
      "4000\n",
      "4250\n",
      "4500\n",
      "4750\n",
      "5000\n",
      "5250\n",
      "5500\n",
      "5750\n",
      "6000\n",
      "6250\n",
      "6500\n",
      "6750\n",
      "7000\n",
      "7250\n",
      "7500\n",
      "7750\n",
      "8000\n",
      "8250\n",
      "8500\n",
      "8750\n",
      "9000\n",
      "9250\n",
      "9500\n",
      "9750\n",
      "10000\n",
      "10250\n",
      "10500\n",
      "10750\n",
      "11000\n",
      "11250\n",
      "11500\n",
      "11750\n",
      "12000\n",
      "12250\n",
      "12500\n",
      "12750\n",
      "13000\n",
      "13250\n",
      "13500\n",
      "13750\n",
      "14000\n",
      "14250\n",
      "14500\n",
      "14750\n",
      "15000\n",
      "15250\n",
      "15500\n",
      "15750\n",
      "16000\n",
      "16250\n",
      "16500\n",
      "16750\n",
      "17000\n",
      "17250\n",
      "17500\n",
      "17750\n",
      "18000\n",
      "18250\n",
      "18500\n",
      "18750\n",
      "19000\n",
      "19250\n",
      "19500\n",
      "19750\n",
      "20000\n",
      "20250\n",
      "20500\n",
      "20750\n",
      "21000\n",
      "21250\n",
      "21500\n",
      "21750\n",
      "22000\n",
      "22250\n",
      "22500\n",
      "22750\n",
      "23000\n",
      "23250\n",
      "23500\n",
      "23750\n",
      "24000\n",
      "24250\n",
      "24500\n",
      "24750\n",
      "25000\n",
      "25250\n",
      "25500\n",
      "25750\n",
      "26000\n",
      "26250\n",
      "26500\n",
      "26750\n",
      "27000\n",
      "27250\n",
      "27500\n",
      "27750\n",
      "28000\n",
      "28250\n",
      "28500\n",
      "28750\n",
      "29000\n",
      "29250\n",
      "29500\n",
      "29750\n",
      "30000\n",
      "30250\n",
      "30500\n",
      "30750\n",
      "31000\n",
      "31250\n",
      "31500\n",
      "31750\n",
      "32000\n",
      "32250\n",
      "32500\n",
      "32750\n",
      "33000\n",
      "33250\n",
      "33500\n",
      "33750\n",
      "34000\n",
      "34250\n",
      "34500\n",
      "34750\n",
      "35000\n",
      "35250\n",
      "35500\n",
      "35750\n",
      "36000\n",
      "36250\n",
      "36500\n",
      "36750\n",
      "37000\n",
      "37250\n",
      "37500\n",
      "37750\n",
      "38000\n",
      "38250\n",
      "38500\n",
      "38750\n",
      "39000\n",
      "39250\n",
      "39500\n",
      "39750\n",
      "40000\n",
      "40250\n",
      "40500\n",
      "40750\n",
      "41000\n",
      "41250\n",
      "41500\n",
      "41750\n",
      "42000\n",
      "42250\n",
      "42500\n",
      "42750\n",
      "43000\n",
      "43250\n",
      "43500\n",
      "43750\n",
      "44000\n",
      "44250\n",
      "44500\n",
      "44750\n",
      "45000\n",
      "45250\n",
      "45500\n",
      "45750\n",
      "46000\n",
      "46250\n",
      "46500\n",
      "46750\n",
      "47000\n",
      "47250\n",
      "47500\n",
      "47750\n",
      "48000\n",
      "48250\n",
      "48500\n",
      "48750\n",
      "49000\n",
      "49250\n",
      "49500\n",
      "49750\n",
      "50000\n",
      "50250\n",
      "50500\n",
      "50750\n",
      "51000\n",
      "51250\n",
      "51500\n",
      "51750\n",
      "52000\n",
      "52250\n",
      "52500\n",
      "52750\n",
      "53000\n",
      "53250\n",
      "53500\n",
      "53750\n",
      "54000\n",
      "54250\n",
      "54500\n",
      "54750\n",
      "55000\n",
      "55250\n",
      "55500\n",
      "55750\n",
      "56000\n",
      "56250\n",
      "56500\n",
      "56750\n",
      "57000\n",
      "57250\n",
      "57500\n"
     ]
    }
   ],
   "source": [
    "data_collect = []\n",
    "last_file = np.nan\n",
    "for i, file in enumerate(target_papers.file.tolist()):\n",
    "    if i in status_prints:\n",
    "        print(i)\n",
    "    if file == last_file:\n",
    "        paper = dat[target_papers.paper_number.iloc[i]]\n",
    "        out_dat = return_passages(paper)\n",
    "        data_collect.extend(out_dat)\n",
    "    else:\n",
    "        with open(file) as infile:\n",
    "            dat = json.load(infile)\n",
    "            paper = dat[target_papers.paper_number.iloc[i]]\n",
    "            out_dat = return_passages(paper)\n",
    "            data_collect.extend(out_dat)\n",
    "            last_file = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>paper_offset</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>doi</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cognition and Mood-Related Behaviors in L3mbtl...</td>\n",
       "      <td>0</td>\n",
       "      <td>4388653</td>\n",
       "      <td>10.1371/journal.pone.0121252</td>\n",
       "      <td>TITLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alterations in histone lysine methylation and ...</td>\n",
       "      <td>65</td>\n",
       "      <td>4388653</td>\n",
       "      <td>10.1371/journal.pone.0121252</td>\n",
       "      <td>ABSTRACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Introduction</td>\n",
       "      <td>1608</td>\n",
       "      <td>4388653</td>\n",
       "      <td>10.1371/journal.pone.0121252</td>\n",
       "      <td>INTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mood spectrum disorders, including depression ...</td>\n",
       "      <td>1621</td>\n",
       "      <td>4388653</td>\n",
       "      <td>10.1371/journal.pone.0121252</td>\n",
       "      <td>INTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malignant Brain Tumor (MBT) domain chromatin ...</td>\n",
       "      <td>2704</td>\n",
       "      <td>4388653</td>\n",
       "      <td>10.1371/journal.pone.0121252</td>\n",
       "      <td>INTRO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  paper_offset    pmcid  \\\n",
       "0  Cognition and Mood-Related Behaviors in L3mbtl...             0  4388653   \n",
       "1  Alterations in histone lysine methylation and ...            65  4388653   \n",
       "2                                       Introduction          1608  4388653   \n",
       "3  Mood spectrum disorders, including depression ...          1621  4388653   \n",
       "4   Malignant Brain Tumor (MBT) domain chromatin ...          2704  4388653   \n",
       "\n",
       "                            doi   section  \n",
       "0  10.1371/journal.pone.0121252     TITLE  \n",
       "1  10.1371/journal.pone.0121252  ABSTRACT  \n",
       "2  10.1371/journal.pone.0121252     INTRO  \n",
       "3  10.1371/journal.pone.0121252     INTRO  \n",
       "4  10.1371/journal.pone.0121252     INTRO  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pool = pd.DataFrame(data_collect)\n",
    "df_pool.columns = ['context', 'paper_offset', 'pmcid', 'doi', 'section']\n",
    "df_pool.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18406892, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_file = open('/data/riddleta/data_sharing_reuse/external/tokenizer.pk', 'rb')\n",
    "tokenizer = pickle.load(tk_file)\n",
    "tk_file.close()\n",
    "df_pool['context'] = df_pool.context.apply(lambda x: tokenizer.tokenize(x))\n",
    "df_pool = df_pool.explode('context')\n",
    "df_pool.shape# all sentence 18406892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pool = df_pool[~df_pool.section.isin(['REF', 'TABLE', 'TITLE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riddleta/miniconda3/envs/data_sharing_reuse/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3050: DtypeWarning: Columns (4,5,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_pmcids = pd.read_csv('/data/riddleta/data_sharing_reuse/external/PMC-ids.csv')\n",
    "df_pmcids['pmcid'] = df_pmcids.PMCID.apply(lambda x: str(x)[3:])\n",
    "df_pool = df_pool.merge(df_pmcids, how='left', on='pmcid')\n",
    "df_pool['pmcid'] = df_pool.pmcid.astype('str')\n",
    "df_pool['offset'] = df_pool.paper_offset.astype('str')\n",
    "df_pool['pmcid-offset'] = df_pool.apply(lambda x: x['pmcid']+'-'+x['offset'], axis=1)\n",
    "df_pool['context'] = df_pool.context.astype('str')\n",
    "df_pool['text'] = df_pool.context.apply(lambda x: sep_urls(x))\n",
    "df_pool['syn_text'] = df_pool.text.apply(lambda x: syns(x))\n",
    "df_pool['all_text'] = df_pool.text + ' ' + df.syn_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pool.text.fillna('', inplace=True)\n",
    "df_pool['has_url'] = df_pool.text.apply(lambda x: extract.has_urls(x))\n",
    "df_pool['has_parenth'] = df_pool.text.apply(lambda x: check_paren(x))\n",
    "df_pool['repo'] = df_pool.text.apply(lambda x: repo_label(x))\n",
    "df_pool.all_text.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pool = cv.transform(df_pool.all_text)\n",
    "one_hots_pool = enc.transform(df_pool[['section', 'Journal Title', 'Year', 'has_url', 'has_parenth', 'repo']])\n",
    "\n",
    "x_pool = hstack([x_pool, one_hots_pool])\n",
    "y_pool_pred = clf.predict(x_pool)\n",
    "pd.Series(y_pool_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pool['data_sharing_pred'] = y_pool_pred\n",
    "df_data_statements = df_pool[df_pool.data_sharing_pred==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements_to_label = df_data_statements.sample(n=500, random_state=42)\n",
    "out_file = statements_to_label[['context', 'paper_offset', 'pmcid', 'doi', 'section', \n",
    "                                'Journal Title', 'text', 'has_url', 'has_parenth', 'repo',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file.to_csv('/data/riddleta/data_sharing_reuse/interim/high_recall_labelling.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_sharing_reuse] *",
   "language": "python",
   "name": "conda-env-data_sharing_reuse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
